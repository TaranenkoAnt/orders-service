Subject: [PATCH] 10_kafka_connector_1
---
Index: docker/read_topics.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/docker/read_topics.sh b/docker/read_topics.sh
new file mode 100644
--- /dev/null	(date 1729262481254)
+++ b/docker/read_topics.sh	(date 1729262481254)
@@ -0,0 +1,10 @@
+#!/bin/bash
+
+################################
+BOOTSTRAP_SERVERS=kafka:29092
+SCHEMA_REGISTRY_URL=http://schema-registry:8081
+
+echo -e "\n*** Sampling messages in Kafka topics ***\n"
+
+echo -e "\n-----v1.public.orders_outbox topic-----"
+docker compose exec connect kafka-avro-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --property schema.registry.url=$SCHEMA_REGISTRY_URL --from-beginning --timeout-ms 10000 --max-messages 5 --topic v1.public.orders_outbox
\ No newline at end of file
Index: debezium/debezium-config.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/debezium/debezium-config.json b/debezium/debezium-config.json
new file mode 100644
--- /dev/null	(date 1729262481249)
+++ b/debezium/debezium-config.json	(date 1729262481249)
@@ -0,0 +1,43 @@
+{
+  "name": "orders-connector",
+  "config": {
+    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
+    "plugin.name": "pgoutput",
+    "database.hostname": "postgres",
+    "database.port": "5432",
+    "database.user": "user",
+    "database.password": "password",
+    "database.dbname": "orders_service_db",
+    "database.server.name": "dbserver1",
+    "table.include.list": "public.orders_outbox, public.heartbeat_table",
+    "topic.prefix": "v1",
+    "value.converter": "io.confluent.connect.avro.AvroConverter",
+    "value.converter.schema.registry.url": "http://schema-registry:8081",
+    "value.converter.schemas.enable": "false",
+    "heartbeat.interval.ms": "5000",
+    "heartbeat.action.query" :"INSERT INTO heartbeat_table (id, updated_at) VALUES (1, NOW()) ON CONFLICT(id) DO UPDATE SET updated_at=EXCLUDED.updated_at;",
+    "slot.name": "postgres_debezium",
+    "publication.name": "orders_outbox_publication",
+    "publication.autocreate.mode": "filtered",
+    "topic.creation.default.partitions": 3,
+    "topic.creation.default.replication.factor": 1,
+    "predicates": "ordersTopic",
+    "predicates.ordersTopic.type": "org.apache.kafka.connect.transforms.predicates.TopicNameMatches",
+    "predicates.ordersTopic.pattern": "v1.public.orders.*",
+    "transforms": "unwrap,PartitionRouting,SetValueSchema",
+    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
+    "transforms.unwrap.add.fields": "lsn,source.ts_ms",
+    "transforms.unwrap.drop.tombstones": "true",
+    "transforms.PartitionRouting.type": "io.debezium.transforms.partitions.PartitionRouting",
+    "transforms.PartitionRouting.partition.payload.fields": "change.order_id",
+    "transforms.PartitionRouting.partition.topic.num": 3,
+    "transforms.PartitionRouting.predicate": "ordersTopic",
+    "transforms.SetValueSchema.type": "org.apache.kafka.connect.transforms.SetSchemaMetadata$Value",
+    "transforms.SetValueSchema.schema.name": "ru.javaops.cloudjava.AvroOrderPlacedEvent",
+    "transforms.SetValueSchema.predicate": "ordersTopic",
+    "message.key.columns": "public.orders_outbox:order_id",
+    "key.converter" : "org.apache.kafka.connect.storage.StringConverter",
+    "key.converter.schemas.enable": false,
+    "tombstones.on.delete": false
+  }
+}
\ No newline at end of file
